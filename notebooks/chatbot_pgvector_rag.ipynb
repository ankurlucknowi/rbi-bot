{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75b27272-7cea-46c6-9a5c-eeb9f6b66f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/anaconda3/lib/python3.11/site-packages (1.28.0)\n",
      "Requirement already satisfied: sentence-transformers==2.2.2 in /opt/anaconda3/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: pypdf in /opt/anaconda3/lib/python3.11/site-packages (4.2.0)\n",
      "Requirement already satisfied: SQLAlchemy in /opt/anaconda3/lib/python3.11/site-packages (2.0.25)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/anaconda3/lib/python3.11/site-packages (from sentence-transformers==2.2.2) (4.39.3)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.11/site-packages (from sentence-transformers==2.2.2) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in /opt/anaconda3/lib/python3.11/site-packages (from sentence-transformers==2.2.2) (2.3.0)\n",
      "Requirement already satisfied: torchvision in /opt/anaconda3/lib/python3.11/site-packages (from sentence-transformers==2.2.2) (0.18.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.11/site-packages (from sentence-transformers==2.2.2) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.11/site-packages (from sentence-transformers==2.2.2) (1.2.2)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.11/site-packages (from sentence-transformers==2.2.2) (1.11.4)\n",
      "Requirement already satisfied: nltk in /opt/anaconda3/lib/python3.11/site-packages (from sentence-transformers==2.2.2) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in /opt/anaconda3/lib/python3.11/site-packages (from sentence-transformers==2.2.2) (0.2.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /opt/anaconda3/lib/python3.11/site-packages (from sentence-transformers==2.2.2) (0.22.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai) (1.10.12)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.11/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/anaconda3/lib/python3.11/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2.31.0)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.1.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.4.2)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.11/site-packages (from nltk->sentence-transformers==2.2.2) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.11/site-packages (from nltk->sentence-transformers==2.2.2) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn->sentence-transformers==2.2.2) (2.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from torchvision->sentence-transformers==2.2.2) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=1.6.0->sentence-transformers==2.2.2) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2.0.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/anaconda3/lib/python3.11/site-packages (from sympy->torch>=1.6.0->sentence-transformers==2.2.2) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai sentence-transformers==2.2.2 pypdf SQLAlchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "932ab1eb-de4d-4266-8cd1-21bff5551da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "from openai import OpenAI\n",
    "from time import perf_counter\n",
    "import numpy as np\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7102f9c7-f2c0-4263-b23b-216a19c67eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_embedding(text, embedding_model, out_type=\"array\"):\n",
    "    text = text.replace(\"\\r\", \" \").replace(\"\\n\", \" \")\n",
    "    embedding = embedding_model.encode(text)\n",
    "    if out_type == \"list\":\n",
    "        return embedding\n",
    "    elif out_type == \"array\":\n",
    "        return np.array(embedding)\n",
    "        \n",
    "def similarity_search_from_emb(emb, engine, match_threshold=0.75, match_count=10):\n",
    "    formatted_str = ', '.join(map(str, emb))\n",
    "    formatted_str = f\"[{formatted_str}]\"\n",
    "    sql = f\"\"\"WITH cte AS (SELECT document_domain,document_name, page_number, sequence, text, (embedding_1024 <#> '{formatted_str}') as similarity \n",
    "    FROM document_embeddings\n",
    "    ORDER BY similarity asc\n",
    "    LIMIT {match_count})\n",
    "    SELECT * FROM cte\n",
    "    WHERE similarity < -{match_threshold}\"\"\"\n",
    "    df = None\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", UserWarning)\n",
    "        df = pd.read_sql(sql=sql, con=engine)    \n",
    "    df.similarity *= -1.0\n",
    "    return df\n",
    "\n",
    "def similarity_search(text, engine,match_threshold=0.75, match_count=10):\n",
    "    start = perf_counter()\n",
    "    #emb = get_embedding(text, embedding_model,out_type=\"list\")\n",
    "    emb = get_embedding(text, embedding_model,out_type=\"array\")\n",
    "    end = perf_counter()\n",
    "    elapsed_time = end - start\n",
    "    start = perf_counter()\n",
    "    df = similarity_search_from_emb(emb, engine, match_threshold=0.75, match_count=match_count)\n",
    "    end = perf_counter()\n",
    "    elapsed_time = end - start\n",
    "    return df\n",
    "\n",
    "def get_surrounding_chunks(engine,document_domain,document_name,sequence, N):\n",
    "    # SQL query to fetch surrounding chunks\n",
    "    seq_min = sequence - N\n",
    "    seq_max = sequence + N\n",
    "    query = f\"\"\"\n",
    "        SELECT document_domain,document_name,Page_Number,sequence,text  FROM document_embeddings\n",
    "        WHERE document_domain = '{document_domain}' AND\n",
    "              document_name = '{document_name}' AND\n",
    "              sequence BETWEEN '{seq_min}' AND '{seq_max}'\n",
    "        ORDER BY document_domain,document_name,sequence ASC\n",
    "    \"\"\" \n",
    "    result = None\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", UserWarning)\n",
    "        result = pd.read_sql(sql=query, con=engine)    \n",
    "    return result\n",
    "    \n",
    "\n",
    "def get_prompt_context_using_rag(query,engine):\n",
    "    df = similarity_search(query,engine)\n",
    "    top_rows = df.head(3)\n",
    "    N = 3\n",
    "    all_chunks = pd.DataFrame()\n",
    "    pd.set_option('display.max_colwidth', None)  # For pandas versions 1.0 and later\n",
    "    for index, row in top_rows.iterrows():\n",
    "        surrounding_chunks = get_surrounding_chunks(engine,row['document_domain'], row['document_name'], row['sequence'], N)\n",
    "        all_chunks = pd.concat([all_chunks, surrounding_chunks], ignore_index=True)\n",
    "    all_chunks.drop_duplicates(subset=['document_name', 'sequence'])\n",
    "    all_chunks.sort_values(by=['document_name', 'page_number', 'sequence'], inplace=True)\n",
    "    all_chunks['text'] = all_chunks.sort_values('sequence').groupby(['document_name', 'page_number'])['text'].transform(lambda x: ' '.join(x))\n",
    "    all_chunks = all_chunks.drop_duplicates(subset=['document_name', 'page_number'])\n",
    "    all_chunks.reset_index(drop=True, inplace=True)\n",
    "    prompt_input = all_chunks.apply(lambda row: f\"Document: {row['document_name']}, Page: {row['page_number']}, Content: {row['text']}\", axis=1).tolist()\n",
    "    return prompt_input[0]\n",
    "\n",
    "def get_response(prompt_input,llm_client):\n",
    "    global messages\n",
    "    messages = [\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\\\n",
    "                 And will always answer the question asked in 'Question:' and \\\n",
    "                 will quote the Document and Page number at the end of the answer,\\\n",
    "                 the Document: and Page: fields precede the content based on which you will answer.\"},\n",
    "                {\"role\": \"user\", \"content\": ''.join(prompt_input)}\n",
    "          ]\n",
    "\n",
    "    response = llm_client.chat.completions.create(\n",
    "                            model = \"gpt-3.5-turbo\",\n",
    "                            messages = messages,\n",
    "                            temperature=0.2,               \n",
    "                     )\n",
    "    \n",
    "    #response_msg = \"llm response here\"\n",
    "    response_msg = response.choices[0].message.content\n",
    "    messages = messages + [{\"role\":'assistant', 'content': response_msg}]\n",
    "    return response_msg\n",
    "\n",
    "\n",
    "def get_answer(query,openai_clien,engine):\n",
    "    query_string = get_prompt_context_using_rag(query,engine)\n",
    "    query_string = query_string + f\" ques: {query}\"\n",
    "    answer = get_response(query_string,openai_client)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a38dcc61-5ccc-4c28-aff9-7b750fb26342",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_domain = \"RBI_Guidelines\"\n",
    "dbname = 'rbi_bot_db'\n",
    "dbuser = 'rbi_bot_user'\n",
    "dbpassword = 'rbi_bot_pwd'\n",
    "dbhost = '127.0.0.1'\n",
    "dbport = 5432\n",
    "chunk_size = 400\n",
    "embedding_model_name = 'thenlper/gte-large'\n",
    "embedding_model = SentenceTransformer(embedding_model_name)\n",
    "db_conn_str = f\"postgresql://{dbuser}:{dbpassword}@{dbhost}:{dbport}/{dbname}\"\n",
    "sql_engine = create_engine(db_conn_str)\n",
    "openai_client = OpenAI(api_key=\"nahi_doonga\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74b2033d-307f-4646-a864-447778c6080c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Is there a limit to the interest rate I can charge a customer on a loan?\n",
      "\n",
      "Yes, there is no specific limit set by the Bank on the interest rates that can be charged by Housing Finance Companies (HFCs) to customers. However, it is mentioned that interest rates beyond a certain level may be considered excessive and unsustainable, not conforming to normal financial practice. HFCs are advised to have internal principles and procedures in place for determining interest rates, processing charges, and other fees, including penal charges. Transparency in communicating terms and conditions to borrowers is also emphasized.\n",
      "\n",
      "(Document: FAIRLENDINGPRACTICE1B9DBE75410B4DA881E6EF953304B6F7.pdf, Page: 10)\n",
      "Question: Can a co-lending partner issue a gold-loan at the customer doorstep?\n",
      "\n",
      "Yes, a co-lending partner can issue a gold loan at the customer's doorstep, provided certain conditions are met. The loan agreement must contain details of the option to be exercised by the borrower, acceptable standards and manner of delivery of gold for repayment. The borrower must repay a part of the Gold (Metal) Loan in physical gold in lots of one kg or more, using locally sourced India Good Delivery Standard (IGDS) or LBMA’s Good Delivery Standards (LGDS) gold. The gold must be delivered on behalf of the borrower to the bank directly by the refiner or a central agency acceptable to the bank, without the borrower's involvement. The borrower must also be informed upfront, in a transparent manner, of the implications of exercising this option. (Document: GMLRB32D8C0B2C6341C0A82BD98289ECBA38.pdf, Page: 1)\n",
      "Yes, you can host a payment gateway for Indian customers using a server located in Pakistan, as long as the country of residence of the beneficiary is not Pakistan. However, it is important to ensure compliance with all relevant regulations and obtain any necessary approvals from the Reserve Bank of India. (Document: 04MD5127742FD0914D54B5EC4ECA8076F325.pdf, Page: 13)\n",
      "Question: Can I create a special scheme for SC ST customers?\n",
      "\n",
      "Yes, you can create a special scheme for SC ST customers. Banks are encouraged to adopt villages with a sizeable population of SC/ST communities for intensive lending. Specific localities within these villages can also be adopted to focus on these communities. Additionally, greater awareness about various schemes formulated by banks should be created among SC/ST borrowers through brochures, field staff visits, and organizing meetings exclusively for them to understand their credit needs and incorporate them into the credit plan. Banks should also not insist on deposits for loan applications under Government-sponsored poverty alleviation schemes/self-employment programs from SCs/STs and ensure that applicable subsidies are not held back while releasing the loan component. It is important to provide institutional support to organizations like the National Scheduled Tribes Finance & Development Corporation and National Scheduled Castes Finance & Development Corporation to achieve the desired objectives (Document: 01MC04E4F5B7C26B47BE93E5D02C5B0D56BE.pdf, Page: 2).\n"
     ]
    }
   ],
   "source": [
    "print(get_answer(\"Is there a limit to the interest-rate I can charge a customer on a loan? \",openai_client,sql_engine))\n",
    "print(get_answer(\"Can a co-lending partner issue a gold-loan at the customer doorstep?\",openai_client,sql_engine))\n",
    "print(get_answer(\"Can I host a payment gateway for Indian customers using a server located in Pakistan?\",openai_client,sql_engine))\n",
    "print(get_answer(\"Can I create a special scheme for SC ST customers?\",openai_client,sql_engine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b4d882-746f-49ea-bcd1-67fa256a0f28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ba6bce-9e52-43f3-8a9f-5cf520dfeba8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
